# DATA-PIPELINE-DEVELOPMENT

*COMPANY*: CODTECH IT SOLUTIONS

*NAME*: SANJANA M NAIK

*INTERN ID*: CT04DH171

*DOMAIN*: DATA SCIENCE

*DURATION*: 4 WEEKS

*MENTOR*: NEELA SANTHOSH


## üìù Project Overview 

As part of my internship at CodTech, I completed Task 1: Data Pipeline Development, which involved building a basic data processing pipeline using Python. The goal was to simulate a real-world scenario by automating the reading of raw CSV data, performing data cleaning and preprocessing, and saving the cleaned output for further analysis. I used tools like Python 3.13, Pandas, and Scikit-learn to handle data manipulation and transformation. The entire logic was written in a Python script (data_pipeline.py) and executed in Visual Studio Code (VS Code).

The dataset used was a sample/mock CSV file, created to replicate real-world data issues such as missing values and inconsistent formatting. I applied data preprocessing techniques to ensure the data was structured and analysis-ready. The folder structure includes sample_data/ for input and cleaned_data/ for output.

This project helped me understand how data pipelines work in real scenarios, especially in tasks related to data preprocessing, ETL (Extract, Transform, Load), and workflow automation. These pipelines are widely used in industries like healthcare, finance, marketing, and retail where large-scale data cleaning and preparation are essential before analysis or modeling.


#OUTPUT

<img width="760" height="699" alt="Image" src="https://github.com/user-attachments/assets/f69b446c-7981-4069-92e1-c9207a612795" />


